{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.matcher.matcher.Matcher at 0x2128368d1c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use matcher to detect rule-based patterns\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to detect a verb formm of lemma 'love' followed by the word 'cats' in any case\n",
    "pattern1 = [\n",
    "    {'LEMMA': 'love', 'POS': 'VERB'},\n",
    "    {'LOWER': 'cats'}\n",
    "]\n",
    "matcher.add('LOVE_CATS', None, pattern1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patternt to one or more instances of 'very' followed by 'happy'\n",
    "pattern2 = [\n",
    "    {'TEXT': 'very', 'OP': '+'},\n",
    "    {'TEXT': 'happy'}\n",
    "]\n",
    "matcher.add('VERRY_HAPPY', None, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9137535031263442622, 1, 3), (2086246540823757615, 6, 8)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('I love cats and I\\'m very happy')\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love cats\n",
      "very happy\n"
     ]
    }
   ],
   "source": [
    "for match_id, start_index, end_index in matches:\n",
    "    print(doc[start_index:end_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15887489236585457779, 3, 5)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case-onsensitive mach pattern for 'golden retriever'\n",
    "pattern = [\n",
    "    {'LOWER': 'golden'},\n",
    "    {'LOWER': 'retriever'}\n",
    "]\n",
    "matcher.add('GOLDEN_RETRIEVER', None, pattern)\n",
    "\n",
    "doc = nlp('I have a Golden Retriever.')\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n",
      "Root token: Retriever\n",
      "Root hread token: have\n",
      "Previous token: a PoS: DET\n",
      "Next token: . PoS: PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Find out more about the span obtained from the match\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print('Matched span:', span.text)\n",
    "    \n",
    "    # Root token of the span\n",
    "    # i.e. when more than one token, the token that decides the category of the phrase\n",
    "    print('Root token:', span.root.text)\n",
    "    \n",
    "    # Head of the root token\n",
    "    # i.e. syantactic parent that governs the phrase\n",
    "    print('Root hread token:', span.root.head.text)\n",
    "    \n",
    "    # PoS information of the previous token before the phrase\n",
    "    print('Previous token:', doc[start-1].text, 'PoS:', doc[start-1].pos_)\n",
    "    \n",
    "    # PoS information of the next token after the phrase\n",
    "    print('Next token:', doc[end].text, 'PoS:', doc[end].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.matcher.phrasematcher.PhraseMatcher at 0x212857589e0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phrase Matcher is a more efficient tool to find squences of words, esp for matching large words lists\n",
    "# It is faster and has direct access to tokens\n",
    "\n",
    "# Instantiate\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2951553348639939143, 3, 5)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of a list of dictionaries, pass a Doc bject as the pattern\n",
    "pattern = nlp('Golden Retriever')\n",
    "matcher.add('DOG', None, pattern)\n",
    "\n",
    "doc = nlp('I hava a Golden Retriever')\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: Golden Retriever\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print('Matched span:', span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3859178723802017889, 7, 9),\n",
       " (6462165356620187099, 27, 30),\n",
       " (3859178723802017889, 39, 41),\n",
       " (6462165356620187099, 44, 47),\n",
       " (6462165356620187099, 82, 85),\n",
       " (6462165356620187099, 102, 105)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [\n",
    "    {'LOWER': 'amazon'},\n",
    "    {'IS_TITLE': True, 'POS': 'PROPN'}\n",
    "]\n",
    "\n",
    "pattern2 = [\n",
    "    {'LOWER': 'ad'},\n",
    "    {'TEXT': '-'},\n",
    "    {'LOWER': 'free'}\n",
    "]\n",
    "\n",
    "doc = nlp(\n",
    "    \"Twitch Prime, the perks program for Amazon Prime members offering free \"\n",
    "    \"loot, games and other benefits, is ditching one of its best features: \"\n",
    "    \"ad-free viewing. According to an email sent out to Amazon Prime members \"\n",
    "    \"today, ad-free viewing will no longer be included as a part of Twitch \"\n",
    "    \"Prime for new members, beginning on September 14. However, members with \"\n",
    "    \"existing annual subscriptions will be able to continue to enjoy ad-free \"\n",
    "    \"viewing until their subscription comes up for renewal. Those with \"\n",
    "    \"monthly subscriptions will have access to ad-free viewing until October 15.\"\n",
    ")\n",
    "\n",
    "matcher.add('AMAZON_PROPN', None, pattern1)\n",
    "matcher.add('AD_FREE', None, pattern2)\n",
    "\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Prime\n",
      "ad-free\n",
      "Amazon Prime\n",
      "ad-free\n",
      "ad-free\n",
      "ad-free\n"
     ]
    }
   ],
   "source": [
    "for pattern_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
